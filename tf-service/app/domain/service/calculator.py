import tensorflow as tf
from app.domain.model.calc_schema import CalcSchema
class Calculator:

    @tf.function
    def plus(self, num1, num2): return tf.add(num1, num2)
    
    @tf.function
    def minus(self, num1, num2): return tf.subtract(num1, num2)
    
    @tf.function
    def multiple(self, num1, num2): return tf.multiply(num1, num2)
    
    @tf.function
    def div(self, num1, num2): return tf.divide(num1, num2)





    def sample(self):
        print("ğŸ‘©ğŸ»ğŸ˜ğŸ‘©ğŸ»â€ğŸ¦° 1. ì—¬ê¸° ê¹Œì§€ ì‹¤í–‰ ë˜ë‚˜ìš”?")
        mnist = tf.keras.datasets.mnist
        print("ğŸ‘©ğŸ»ğŸ˜ğŸ‘©ğŸ»â€ğŸ¦° 2. ì—¬ê¸° ê¹Œì§€ ì‹¤í–‰ ë˜ë‚˜ìš”?")
        (x_train, y_train),(x_test, y_test) = mnist.load_data()
        print("ğŸ‘©ğŸ»ğŸ˜ğŸ‘©ğŸ»â€ğŸ¦° 3. ì—¬ê¸° ê¹Œì§€ ì‹¤í–‰ ë˜ë‚˜ìš”?")
        x_train, x_test = x_train / 255.0, x_test / 255.0
        print("ğŸ‘©ğŸ»ğŸ˜ğŸ‘©ğŸ»â€ğŸ¦° 4. ì—¬ê¸° ê¹Œì§€ ì‹¤í–‰ ë˜ë‚˜ìš”?")
        model = tf.keras.models.Sequential([
        tf.keras.layers.Flatten(input_shape=(28, 28)),
        tf.keras.layers.Dense(128, activation='relu'),
        tf.keras.layers.Dropout(0.2),
        tf.keras.layers.Dense(10, activation='softmax')
        ])
        print("ğŸ‘©ğŸ»ğŸ˜ğŸ‘©ğŸ»â€ğŸ¦° 5. ì—¬ê¸° ê¹Œì§€ ì‹¤í–‰ ë˜ë‚˜ìš”?")
        model.compile(optimizer='adam',
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy'])
        print("ğŸ‘©ğŸ»ğŸ˜ğŸ‘©ğŸ»â€ğŸ¦° 6. ì—¬ê¸° ê¹Œì§€ ì‹¤í–‰ ë˜ë‚˜ìš”?")
        model.fit(x_train, y_train, epochs=5)
        print("ğŸ‘©ğŸ»ğŸ˜ğŸ‘©ğŸ»â€ğŸ¦° 7. ì—¬ê¸° ê¹Œì§€ ì‹¤í–‰ ë˜ë‚˜ìš”?")
        model.evaluate(x_test, y_test)
        print("ğŸ‘©ğŸ»ğŸ˜ğŸ‘©ğŸ»â€ğŸ¦° 8. ì‹¤í–‰ ëë")

    
    
